# configs/train.yaml
# Refactored configuration for training CleanUNet2 with PyTorch Lightning.
# Comments are in English and keys are grouped for clarity.

# ----------------------
# Trainer configuration
# ----------------------
trainer:
  # 'auto' will use GPU if available, otherwise CPU
  accelerator: "auto"
  # Use an integer (number of devices) or "auto" depending on your environment
  devices: 1
  max_epochs: 10000
  # Optionally use max_steps instead of max_epochs
  # max_steps: 1000000
  # Numerical precision: choose "32-true" (full float32) or "16-mixed" for AMP
  precision: "32-true"
  # How often (in steps) Lightning logs metrics
  log_every_n_steps: 100
  # Validate every N epochs (float allowed for fraction of epoch)
  check_val_every_n_epoch: 10
  # Gradient clipping to stabilize training (None or numeric)
  gradient_clip_val: 1.0
  # Deterministic flags (helpful for reproducibility; may slow down training)
  deterministic: false
  benchmark: true

# ----------------------
# Global / runtime
# ----------------------
seed: 1234            # global seed for reproducibility
checkpoint_dir: "logs/checkpoints"  # default directory for checkpoints
logging_dir: "logs"   # base dir for loggers (TensorBoard, etc.)

# ----------------------
# Model & optimizer hyperparameters
# ----------------------
model:
  # Learning rate used by the optimizer (AdamW in the training script)
  lr: 1e-5
  # Sample rate of audio data
  sample_rate: 16000

  # Select the conditioning method here:
  # Options: "addition", "concatenation", "film"
  conditioning_type: "addition"

  # Loss configuration grouped for clarity
  loss_config:
    ell_p: 1                 # 1 -> L1, 2 -> L2
    ell_p_lambda: 1.0        # weight of the waveform reconstruction loss
    stft_lambda: 1.0         # weight for STFT-based losses inside CleanUNet2Loss
    sc_lambda: 0.5           # weight for spectral convergence inside MR-STFT
    mag_lambda: 0.5          # weight for magnitude (log-magnitude) inside MR-STFT
    # Multi-resolution STFT parameters (must be same length lists)
    stft_config:
      fft_sizes: [512, 1024, 2048]
      hop_sizes: [50, 120, 240]
      win_lengths: [240, 600, 1200]

# ----------------------
# Data configuration
# ----------------------
data:
  data_dir: "/home/fred/Projetos/DATASETS/VoiceBank-DEMAND-16k/"
  train_list_path: "filelists/train.csv"
  val_list_path: "filelists/test.csv"
  batch_size: 10
  num_workers: 8
  persistent_workers: true
  # Optional: segment length (samples) used by dataset sampling (if supported)
  #segment_size: 16384

# ----------------------
# Callbacks
# ----------------------
callbacks:
  # Save best checkpoint based on validation loss
  best_checkpoint:
    _target_: "pytorch_lightning.callbacks.ModelCheckpoint"
    monitor: "val_loss"
    dirpath: "logs/checkpoints"
    filename: "best-model-{epoch:02d}-{val_loss:.4f}"
    save_top_k: 1
    mode: "min"
  # Periodic checkpointing (every N epochs)
  periodic_checkpoint:
    _target_: "pytorch_lightning.callbacks.ModelCheckpoint"
    dirpath: "logs/checkpoints"
    filename: "epoch-{epoch:04d}"
    every_n_epochs: 10
    save_top_k: 3
    save_last: true
    monitor: "val_loss"
    mode: "min"
    # monitor/mode not needed for simple periodic saving

  # Example early stopping (commented by default)
  # early_stopping:
  #   _target_: "pytorch_lightning.callbacks.EarlyStopping"
  #   monitor: "val_loss"
  #   patience: 20
  #   mode: "min"

# ----------------------
# Logger
# ----------------------
logger:
  _target_: "pytorch_lightning.loggers.TensorBoardLogger"
  save_dir: "logs"
  name: "cleanunet2"

logger:
  # Choose: 'tensorboard', 'wandb' or 'both' (for both)
  choice: "tensorboard"
  
  tensorboard:
    _target_: pytorch_lightning.loggers.TensorBoardLogger
    save_dir: "logs"
    name: "cleanunet2"
    default_hp_metric: false

  wandb:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: "CleanUNet2_Project"
    name: "cleanunet2_run"
    save_dir: "logs"
    offline: false  # Change for true if no internet
    log_model: true

# ----------------------
# Resume / checkpoints
# ----------------------
# Set this to a checkpoint path to resume training
# resume_from_checkpoint: "logs/checkpoints/last.ckpt"

